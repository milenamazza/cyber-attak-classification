{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"SydCnitAeLO_","executionInfo":{"status":"ok","timestamp":1738587539212,"user_tz":-60,"elapsed":37144,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["%%capture\n","import pandas as pd\n","import numpy as np\n","import warnings\n","from google.colab import drive\n","import ipaddress\n","\n","warnings.filterwarnings('ignore')\n","drive.mount('/content/drive')\n","\n","FILEPATH = \"/content/drive/MyDrive/data analytics/svm_3.0/results_0.csv\""]},{"cell_type":"markdown","metadata":{"id":"oK4AXarlSXJf"},"source":["# Creazione df result"]},{"cell_type":"code","source":["def create_empty_df(filepath):\n","  \"\"\"\n","  Crea un DataFrame vuoto e lo salva in un file CSV.\n","  \"\"\"\n","  # Definisci le colonne del DataFrame\n","  columns = ['ds', 'random', 'outlier', 'dim_reduction', 'pca_threshold', 'degree', 'scaler', 'kernel', 'C', 'gamma', 'target count']\n","\n","  # Crea un DataFrame vuoto\n","  results_df = pd.DataFrame(columns=columns)\n","\n","  # Salva il DataFrame in formato CSV\n","  results_df.to_csv(filepath, index=False)\n","\n","  print(f\"DataFrame creato e salvato in {filepath}\")\n","\n","create_empty_df(FILEPATH)"],"metadata":{"id":"_PR2nWm7RUOd","executionInfo":{"status":"ok","timestamp":1738587540973,"user_tz":-60,"elapsed":1766,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b945bf5-b84e-47e8-8f19-751884f8b1ee"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["DataFrame creato e salvato in /content/drive/MyDrive/data analytics/svm_3.0/results_0.csv\n"]}]},{"cell_type":"markdown","metadata":{"id":"FJgi_sXUxr9c"},"source":["# Data Cleaning\n","Scelta colonne, cast delle colonne e gestione dei valori nulli\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"05w29vRUj2Q9","executionInfo":{"status":"ok","timestamp":1738587540974,"user_tz":-60,"elapsed":9,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["# Funzione per determinare il tipo di dato di una colonna\n","def type_data(column):\n","    default_val = [np.nan, '-']\n","    column = column[~column.isin(default_val)]\n","    unique_count = column.nunique()\n","    if is_binary_dtype(column):\n","        return 'Binario'\n","    if  is_numeric_dtype(column):\n","        return 'Numerico Discreto' if pd.api.types.is_integer_dtype(column) else 'Numerico Continuo'\n","    if is_category_dtype(column):\n","        return 'Categorico'\n","    return 'Unknown'\n","\n","# Funzioni ausiliarie per verificare il tipo di dato\n","def is_numeric_dtype(column):\n","    return pd.api.types.is_numeric_dtype(column)\n","\n","def is_binary_dtype(column):\n","    return set(column.unique()) == {True, False}\n","\n","def is_category_dtype(column):\n","    return pd.api.types.is_object_dtype(column) or pd.api.types.is_categorical_dtype(column)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"l-_JHS8nz5Uv","executionInfo":{"status":"ok","timestamp":1738587540974,"user_tz":-60,"elapsed":7,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["def clean_service_columns(data):\n","    service_related_cols = {}\n","    categorial_columns = data.select_dtypes(exclude=np.number).columns\n","    categorial_columns = categorial_columns.drop(['http_orig_mime_types', 'http_resp_mime_types'])\n","    for col in categorial_columns:\n","      for prefix in ['dns', 'http', 'ssl']:\n","        if col.startswith(prefix) and not pd.api.types.is_numeric_dtype(col):\n","          if prefix not in service_related_cols:\n","            service_related_cols[prefix] = []\n","          service_related_cols[prefix].append(col)\n","    for col in data.columns:\n","        for service, columns in service_related_cols.items():\n","            if col in columns and f\"service_{service}\" in data.columns:\n","                data.loc[~data[f\"service_{service}\"], col] = '/'\n","    return data\n","\n","def boolean_mapping(value, def_val=None):\n","    if value in {True, False}:\n","        return value\n","    if value == 'T':\n","        return True\n","    if value == 'F':\n","        return False\n","    return def_val if def_val is not None else value\n","\n","def categorize_ports(df, port_columns):\n","    port_bins = [0, 1023, 49151, 65535]\n","    port_labels = [\"Well-Known\", \"Registered\", \"Dynamic\"]\n","    for col in port_columns:\n","        df[col] = pd.cut(df[col], bins=port_bins, labels=port_labels, right=True)\n","    return df\n","\n","\n","def categorize_ip(ip):\n","    try:\n","        ip_obj = ipaddress.ip_address(ip)\n","        if ip_obj.is_loopback:\n","            return \"Loopback\"\n","        if ip_obj.is_private:\n","            return \"Private\"\n","        if ip_obj.is_multicast:\n","            return \"Multicast\"\n","        if ip_obj.is_reserved:\n","            return \"Reserved\"\n","        if ip_obj.is_link_local:\n","            return \"Link-Local\"\n","        return \"Public\"\n","    except ValueError:\n","        return \"Invalid\"\n","\n","def df_mapping(df):\n","  rcode_mapping = {0: 'No Error', 2: 'ServerFailure', 3: 'NameError', 5: 'Refuse'}\n","  qclass_mapping = {0: '-', 1: 'IN', 32769: 'CH'}\n","  qtype_mapping = {0: '-', 1: 'A', 2: 'NS', 5: 'CNAME', 28: 'AAAA', 255: 'ANY'}\n","\n","  for col in df.columns:\n","    if col in ['dns_RD', 'dns_RA', 'dns_AA', 'dns_rejected','ssl_established','ssl_resumed', 'weird_notice', 'http_trans_depth']:\n","      df[col] = df[col].map(lambda x: boolean_mapping(x, def_val=False)).astype(str)\n","    if col in ['http_status_code', 'weird_addl', 'http_trans_depth']:\n","      df[col] = df[col].astype(str)\n","    if col == 'dns_qclass':\n","      df[col] = df[col].apply(lambda x: qclass_mapping.get(x, None))\n","    if col == 'dns_qtype':\n","      df[col] = df[col].apply(lambda x: qtype_mapping.get(x, None))\n","    if col == 'dns_rcode':\n","      df[col] = df[col].apply(lambda x: rcode_mapping.get(x, None))\n","    if col in ['src_ip', 'dst_ip']:\n","      df[col] = df[col].apply(categorize_ip)\n","    if col == 'src_bytes':\n","      df = df[df['src_bytes'] != '0.0.0.0']\n","      df['src_bytes'] = df['src_bytes'].astype(int)\n","  df = categorize_ports(df, ['src_port', 'dst_port'])\n","  return df\n","\n","def data_cleaning(df):\n","    services = df['service'].str.split(';').explode().unique()  # Estrazione di tutti i servizi unici\n","    for service in services:\n","        df[f'service_{service}'] = df['service'].apply(lambda x: service in x.split(';'))\n","\n","    df.drop(['http_referrer', 'service', 'service_-'], axis=1, inplace=True, errors='ignore')\n","    df.drop( ['ts', 'ssl_subject', 'ssl_issuer', 'dns_query', 'http_uri', 'http_user_agent', 'weird_name', 'label'],\n","             axis=1, inplace=True, errors='ignore')\n","\n","    df = df_mapping(df)\n","    df = clean_service_columns(df)\n","\n","    return df"]},{"cell_type":"code","source":["def replace_default_new(df, info):\n","\n","    mode_values = {}\n","    if info == 'mode' or info=='mode_all':\n","      for col in df.columns:\n","        if is_category_dtype(df[col]) or is_binary_dtype(df[col]):\n","            valid_values = df[(df[col] != '/') & (df[col] != '-')][col]\n","            mode_value = valid_values.mode()[0] if not valid_values.empty else '-'  # Usa '-' se non c'è moda\n","            mode_values[col] = mode_value\n","\n","            # Sostituzione valori\n","            df[col] = df[col].replace('-', mode_value)\n","            if info == 'mode_all':\n","              df[col] = df[col].replace('/', mode_value)\n","\n","    # Salva le mode con joblib\n","    joblib.dump(mode_values, \"mode.pk\")\n","\n","    return df\n","\n","\n","def apply_saved_modes(val, info):\n","\n","    if info == 'mode' or info=='mode_all':\n","      mode_values = joblib.load(\"mode.pk\")\n","      # Applica le mode ai nuovi dati\n","      for col, mode_value in mode_values.items():\n","          if col in val.columns:\n","              val[col] = val[col].replace('-', mode_value)\n","              if info == 'mode_all':\n","                val[col] = val[col].replace('/', mode_value)\n","    return val"],"metadata":{"id":"qYX3qCVdyIyF","executionInfo":{"status":"ok","timestamp":1738587540974,"user_tz":-60,"elapsed":7,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"d7d7wavGkHeZ","executionInfo":{"status":"ok","timestamp":1738587565203,"user_tz":-60,"elapsed":24235,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["df=pd.read_csv('/content/drive/MyDrive/data analytics/train_dataset.csv')\n","df = data_cleaning(df)"]},{"cell_type":"markdown","metadata":{"id":"EprNSrtG020W"},"source":["# Divisione val e train"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ijcFM87B01a8","executionInfo":{"status":"ok","timestamp":1738587567465,"user_tz":-60,"elapsed":2266,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Definisci le features (X) e il target (y)\n","X = df.drop('type', axis=1)  # Assumi che 'label' sia la colonna del target\n","y = df['type']\n","\n","# Dividi il dataset in train e test set\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=19)\n","\n","# Unisci X_train e y_train\n","train_df = pd.concat([X_train, y_train], axis=1)\n","\n","# Unisci X_test e y_test\n","test_df = pd.concat([X_val, y_val], axis=1)"]},{"cell_type":"markdown","metadata":{"id":"xuYxMmVa9Yyh"},"source":["# Pipline"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"6yfSMEUnyn3Q","executionInfo":{"status":"ok","timestamp":1738587568987,"user_tz":-60,"elapsed":1525,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer, LabelEncoder, Normalizer\n","from sklearn.preprocessing import FunctionTransformer\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","from sklearn.decomposition import PCA\n","from sklearn.utils import shuffle\n","import joblib\n","from imblearn.over_sampling import SMOTE,  BorderlineSMOTE, RandomOverSampler\n","from imblearn.under_sampling import RandomUnderSampler"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hYW2GAR10g9D","executionInfo":{"status":"ok","timestamp":1738587568989,"user_tz":-60,"elapsed":12,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["#rimozione outlier per classe\n","def remove_outliers(x, y, out):\n","    x_train = x.copy()\n","    y_train = y.copy()\n","\n","    df = pd.concat([x_train, y_train], axis=1)\n","    numeric_cols = x_train.select_dtypes(include=np.number).columns\n","\n","    # Controlla se non deve essere applicata nessuna rimozione\n","    if out == 'no':\n","        return x, y\n","\n","    if out == 'base':\n","      #rimozione outlier piÃ¹ ASSURDI\n","      before = df.shape[0]\n","      df = df[df['duration'] < 1000]\n","      df = df[df['src_bytes']<100000000]\n","      df = df[df['dst_bytes']<100000000]\n","      df = df[df['missed_bytes']<100000000]\n","      df = df[df['src_pkts']<20000]\n","      df = df[df['dst_pkts']<20000]\n","      df = df[df['src_ip_bytes']<1000000]\n","      df = df[df['dst_ip_bytes']<1000000]\n","      print('  Rimosse ',before-df.shape[0],' istanze')\n","      x_train = df.drop('type', axis=1)\n","      y_train = df['type']\n","      return x_train, y_train\n","\n","    filtered_data = []\n","    # Itera su ciascuna classe\n","    for cls in df['type'].unique():\n","        class_df = df[df['type'] == cls]\n","        before = class_df.shape[0]\n","\n","        if out == 'iqr':\n","            for col in numeric_cols:\n","                Q1 = class_df[col].quantile(0.25)\n","                Q3 = class_df[col].quantile(0.75)\n","                IQR = Q3 - Q1\n","                lower_bound = Q1 - 1.5 * IQR\n","                upper_bound = Q3 + 1.5 * IQR\n","                class_df = class_df[(class_df[col] >= lower_bound) & (class_df[col] <= upper_bound)]\n","\n","        elif out == 'percentile':\n","            for col in numeric_cols:\n","                lower_bound = class_df[col].quantile(0.01)\n","                upper_bound = class_df[col].quantile(0.99)\n","                class_df = class_df[(class_df[col] >= lower_bound) & (class_df[col] <= upper_bound)]\n","\n","        elif out == 'isolation_forest':\n","            from sklearn.ensemble import IsolationForest\n","            iso = IsolationForest(contamination=0.05, random_state=19)\n","            numeric_data = class_df[numeric_cols]\n","            class_df['outlier'] = iso.fit_predict(numeric_data)\n","            class_df = class_df[class_df['outlier'] == 1].drop(columns=['outlier'])\n","\n","        elif out == 'dynamic_threshold':\n","            for col in numeric_cols:\n","                mean = class_df[col].mean()\n","                std = class_df[col].std()\n","                lower_bound = mean - 3 * std\n","                upper_bound = mean + 3 * std\n","                class_df = class_df[(class_df[col] >= lower_bound) & (class_df[col] <= upper_bound)]\n","\n","        filtered_data.append(class_df)\n","\n","    # Combina i dati filtrati per ciascuna classe\n","    filtered_df = pd.concat(filtered_data)\n","\n","    x_train = filtered_df.drop('type', axis=1)\n","    y_train = filtered_df['type']\n","\n","    return x_train, y_train"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"G1jZXJG_ysK9","executionInfo":{"status":"ok","timestamp":1738587568990,"user_tz":-60,"elapsed":13,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["# scaling and normalization\n","def scale_train_data(x_train, y_train, scaling_method):\n","    scaled_df = x_train.copy()\n","\n","    numeric_columns = x_train.select_dtypes(include=np.number).columns\n","    if len(numeric_columns) == 0:\n","        print(\"  Warning: No numeric columns to scale. Returning original DataFrame.\")\n","        return scaled_df, y_train\n","\n","    if scaling_method == 'none':\n","        print(\"No scaling applied.\")\n","        return scaled_df, y_train\n","    elif scaling_method == 'standard':\n","        scaler = StandardScaler()\n","    elif scaling_method == 'minmax':\n","        scaler = MinMaxScaler()\n","    elif scaling_method == 'quantile':\n","        scaled_df = pd.concat([scaled_df, y_train], axis=1)\n","        scaled_df = scaled_df.sort_values(by='src_bytes')\n","        y_train = scaled_df['type']\n","        scaled_df = scaled_df.drop('type', axis=1)\n","        scaler = QuantileTransformer(output_distribution='uniform', random_state=19)\n","    elif scaling_method == 'l1':\n","        scaler = Normalizer(norm='l1')\n","    elif scaling_method == 'l2':\n","        scaler = Normalizer(norm='l2')\n","    else:\n","        raise ValueError(f\"Metodo di scaling '{scaling_method}' non supportato.\")\n","\n","    if scaled_df[numeric_columns].shape[0] < 1:\n","        print(\"  Warning: Not enough samples to fit the scaler. Returning original DataFrame.\")\n","        return scaled_df, y_train\n","\n","    if scaling_method == 'l1' or scaling_method == 'l2':\n","        scaled_df = scaler.fit_transform(scaled_df)\n","    else:\n","        scaled_df[numeric_columns] = scaler.fit_transform(scaled_df[numeric_columns])\n","    joblib.dump(scaler, \"scaler.pkl\")\n","    return scaled_df, y_train\n","\n","# carica scaler e effettua scaling\n","def scale_validation_data(x_val, y_val, scaling_method):\n","    if scaling_method == 'quantile':\n","        x_val = pd.concat([x_val, y_val], axis=1)\n","        x_val = x_val.sort_values(by='src_bytes')\n","        y_val = x_val['type']\n","        x_val = x_val.drop('type', axis=1)\n","\n","    numeric_columns = x_val.select_dtypes(include=np.number).columns\n","    if scaling_method == 'none':\n","        print(\"No scaling applied to validation data.\")\n","        return x_val, y_val\n","\n","    scaler = joblib.load(\"scaler.pkl\")\n","\n","    if scaling_method == 'l1' or scaling_method == 'l2':\n","        x_val = scaler.transform(x_val)\n","    else:\n","        x_val[numeric_columns] = scaler.transform(x_val[numeric_columns])\n","    return x_val, y_val"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"92oPrwzabh3i","executionInfo":{"status":"ok","timestamp":1738587568990,"user_tz":-60,"elapsed":12,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["# ENCODING\n","def encode_categorical_train_data(x_train):\n","    categorical_columns = x_train.select_dtypes(include=['object', 'category']).columns\n","\n","    if len(categorical_columns) > 0:\n","        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n","        encoder.fit(x_train[categorical_columns])\n","        joblib.dump(encoder, \"onehot_encoder.pkl\")\n","        x_train_encoded = encoder.transform(x_train[categorical_columns])\n","        encoded_feature_names = encoder.get_feature_names_out(categorical_columns)\n","        x_train_encoded_df = pd.DataFrame(x_train_encoded, columns=encoded_feature_names, index=x_train.index)\n","        x_train = x_train.drop(columns=categorical_columns)\n","        x_train = pd.concat([x_train, x_train_encoded_df], axis=1)\n","\n","    return x_train\n","\n","def encode_categorical_validation_data(x_val):\n","    categorical_columns = x_val.select_dtypes(include=['object', 'category']).columns\n","    encoder = joblib.load(\"onehot_encoder.pkl\")\n","\n","    if len(categorical_columns) > 0:\n","        x_val_encoded = encoder.transform(x_val[categorical_columns])\n","        encoded_feature_names = encoder.get_feature_names_out(categorical_columns)\n","        x_val_encoded_df = pd.DataFrame(x_val_encoded, columns=encoded_feature_names, index=x_val.index)\n","        x_val = x_val.drop(columns=categorical_columns)\n","        x_val = pd.concat([x_val, x_val_encoded_df], axis=1)\n","\n","    return x_val"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"vbCAdHq90VFz","executionInfo":{"status":"ok","timestamp":1738587568990,"user_tz":-60,"elapsed":12,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["# BILANCIAMENTO\n","def balance_data(x_train, y_train, target_count, num_datasets, random_seed):\n","    smote = SMOTE(random_state=random_seed)\n","    oversampler = RandomOverSampler(random_state=random_seed)\n","\n","    class_counts = pd.Series(y_train).value_counts()\n","    smote_classes = [cls for cls in class_counts.index if class_counts[cls] < target_count / 2]\n","\n","    if smote_classes:\n","        smote_strategy = {cls: target_count for cls in smote_classes}\n","        smote = SMOTE(sampling_strategy=smote_strategy, random_state=random_seed)\n","        x_train, y_train = smote.fit_resample(x_train, y_train)\n","        class_counts = pd.Series(y_train).value_counts()\n","\n","    over_classes = [cls for cls in class_counts.index if class_counts[cls] < target_count]\n","    if over_classes:\n","        over_strategy = {cls: target_count for cls in over_classes}\n","        oversampler = RandomOverSampler(sampling_strategy=over_strategy, random_state=random_seed)\n","        x_train, y_train = oversampler.fit_resample(x_train, y_train)\n","\n","    datasets = []\n","    for i in range(num_datasets):\n","        undersampler = RandomUnderSampler(sampling_strategy={cls: target_count for cls in pd.Series(y_train).value_counts().index}, random_state=random_seed + i)\n","        x_resampled, y_resampled = undersampler.fit_resample(x_train, y_train)\n","        x_resampled, y_resampled = shuffle(x_resampled, y_resampled, random_state=random_seed + i)\n","        datasets.append((x_resampled, y_resampled))\n","\n","\n","\n","    return datasets"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Atst5e5-0c_H","executionInfo":{"status":"ok","timestamp":1738587568990,"user_tz":-60,"elapsed":11,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["# PCA\n","def apply_pca_train(x_train, random_state, pca_threshold=0.99):\n","    pca = PCA(random_state=random_state)\n","    pca.fit(x_train)\n","    cumulative_variance = pca.explained_variance_ratio_.cumsum()\n","    n_components = (cumulative_variance >= pca_threshold).argmax() + 1\n","    pca = PCA(n_components=n_components, random_state=random_state)\n","    transformed_data = pca.fit_transform(x_train)\n","    transformed_data = transformed_data.astype(np.float32)\n","\n","    print(f\"  Numero di colonne selezionate (componenti principali): {n_components}\")\n","    joblib.dump(pca, \"pca_model.pkl\")\n","    return pd.DataFrame(transformed_data, columns=[f\"PC{i+1}\" for i in range(n_components)])\n","\n","def apply_pca_validation(x_val):\n","    pca = joblib.load(\"pca_model.pkl\")\n","    x_val = pca.transform(x_val)\n","    x_val = x_val.astype(np.float32)\n","    return x_val\n","\n","# LDA\n","def apply_lda_train(x_train, y_train, lda_components=None):\n","    lda = LDA(n_components=lda_components)\n","    lda.fit(x_train, y_train)\n","    transformed_data = lda.transform(x_train)\n","    transformed_data = transformed_data.astype(np.float32)\n","\n","    n_components = transformed_data.shape[1]\n","    print(f\"  Numero di colonne selezionate (componenti discriminanti): {n_components}\")\n","    joblib.dump(lda, \"lda_model.pkl\")\n","    return pd.DataFrame(transformed_data, columns=[f\"LD{i+1}\" for i in range(n_components)])\n","\n","def apply_lda_validation(x_val):\n","    lda = joblib.load(\"lda_model.pkl\")\n","    x_val = lda.transform(x_val)\n","    x_val = x_val.astype(np.float32)\n","    return x_val"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"YueC9OPp9afg","executionInfo":{"status":"ok","timestamp":1738587568990,"user_tz":-60,"elapsed":11,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["def preprocessing_pipeline(x_train, y_train, x_validation, y_validation, scaling_method, use_pca, pca_threshold, target_count=20000, num_datasets=1, random_seed=19):\n","    # Encoding delle feature\n","    x_train = encode_categorical_train_data(x_train)\n","    x_validation = encode_categorical_validation_data(x_validation)\n","\n","    # Bilanciamento\n","    datasets = balance_data(x_train, y_train, target_count, num_datasets, random_seed)\n","    validation = []\n","    data = []\n","    i = 0\n","\n","    for x_train, y_train in datasets:\n","      print(f\"  Dataset bilanciato {i+1}:\")\n","      i+=1\n","      # Scaling\n","      x_train, y_train = scale_train_data(x_train, y_train, scaling_method)\n","      x_val, y_val = scale_validation_data(x_validation, y_validation, scaling_method)\n","\n","      if use_pca == 'PCA':\n","          x_train = apply_pca_train(x_train, random_state=random_seed, pca_threshold=pca_threshold)\n","          x_val = apply_pca_validation(x_val)\n","      elif use_pca == 'LDA':\n","          x_train = apply_lda_train(x_train, y_train)\n","          x_val = apply_lda_validation(x_val)\n","\n","      # Bilanciamento\n","      data.append((x_train, y_train))\n","      validation.append((x_val, y_val))\n","    return data, validation\n"]},{"cell_type":"markdown","metadata":{"id":"lTUGMeKlHm1S"},"source":["# Train"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"jez8IsOIKtHp","executionInfo":{"status":"ok","timestamp":1738587568990,"user_tz":-60,"elapsed":10,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["import os\n","\n","# Verifica se una combinazione è già presente nel file CSV.\n","def is_combination_tested(filepath, new_row):\n","  existing_results = pd.read_csv(filepath)\n","  # Colonne per la comparazione\n","  comparison_columns = ['ds', 'random', 'outlier', 'dim_reduction', 'pca_threshold', 'scaler', 'n_neighbors', 'metric', 'weights', 'target count', 'info']\n","  new_row['pca_threshold'] = str(new_row['pca_threshold'])\n","  # Verifica se la combinazione esiste già\n","  is_tested = ((existing_results[comparison_columns] == pd.DataFrame([new_row])[comparison_columns].iloc[0]).all(axis=1).any())\n","  if is_tested:\n","      print(\"  Configurazione già testata, salto...\")\n","  return is_tested\n","\n","def append_and_save_results(filepath, new_row):\n","  results_df = pd.read_csv(filepath)\n","  results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n","  results_df.to_csv(filepath, index=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Pg2hqus-HmOT","executionInfo":{"status":"ok","timestamp":1738587568990,"user_tz":-60,"elapsed":10,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","from itertools import product\n","\n","\n","def evaluate_model(model, x_train, y_train, x_val, y_val):\n","  # Predizioni e metriche sul validation set\n","  y_pred_val = model.predict(x_val)\n","  score_val = accuracy_score(y_val, y_pred_val)\n","  report = classification_report(y_val, y_pred_val, output_dict=True)\n","\n","  # Predizioni e metriche sul training set\n","  y_pred_train = model.predict(x_train)\n","  train_score = accuracy_score(y_train, y_pred_train)\n","\n","  print(f\" Validation score: {score_val} - Train score {train_score}\")\n","  return {'validation_score': score_val, 'train_score': train_score, 'classification_report': report}\n","\n","import time\n","import threading\n","def train_svm_with_grid(x_train, y_train, x_val, y_val, param_grid, metadata):\n","  keys, values = zip(*param_grid.items())\n","  param_combinations = [dict(zip(keys, v)) for v in product(*values)]\n","\n","  best_score = -float('inf')\n","  best_model = None\n","  best_report = None\n","\n","  for params in param_combinations:\n","    print(f\"Valutando configurazione: {params}\")\n","    nan_row = {'accuracy': np.nan, 'precision': np.nan, 'recall': np.nan, 'f1': np.nan, 'train_score': np.nan}\n","    new_row = metadata.copy()\n","    new_row.update(params)\n","\n","    if True:\n","      model = SVC(**params, random_state=new_row['random'])\n","      result_container = {}\n","\n","      def fit_model():\n","        try:\n","          model.fit(x_train, y_train)\n","          result_container['model'] = model\n","        except Exception as e:\n","          result_container['error'] = e\n","      thread = threading.Thread(target=fit_model)\n","      thread.start()\n","      thread.join(timeout=2700)  # 2700 secondi = 45 minuti\n","\n","      if thread.is_alive():\n","        print(f\"  Configurazione interrotta: superato il limite di 45 minuti.\")\n","        thread = None\n","        new_row.update(nan_row)\n","      elif 'error' in result_container:\n","        print(f\"  Errore durante l'addestramento per configurazione {params}: {result_container['error']}\")\n","        new_row.update(nan_row)\n","      else:\n","        results = evaluate_model(result_container['model'], x_train, y_train, x_val, y_val)\n","        new_row.update({\n","            'accuracy': results['classification_report']['accuracy'],\n","            'precision': results['classification_report']['weighted avg']['precision'],\n","            'recall': results['classification_report']['weighted avg']['recall'],\n","            'f1': results['classification_report']['weighted avg']['f1-score'],\n","            'train_score': results['train_score']\n","        })\n","\n","        if results['validation_score'] > best_score:\n","          best_score = results['validation_score']\n","          best_model = result_container['model']\n","          best_report = results['classification_report']\n","\n","      append_and_save_results(FILEPATH, new_row)\n","\n","  return best_model, best_score, best_report"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"7O71MA0xtwq_","executionInfo":{"status":"ok","timestamp":1738587568991,"user_tz":-60,"elapsed":10,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"outputs":[],"source":["def apply(x_train, y_train, x_val, y_val, scaling_methods, param_grid,\n","  dim_reduction=['no'], pca_threshold=0.99, target_count=20000, num_datasets=1,\n","  random_seed=19, outs=['no'], info=''):\n","  \"\"\"\n","  Esegue l'intera pipeline di preprocessing, training e valutazione.\n","  \"\"\"\n","  results = {}\n","  x_train_fix = x_train\n","  x_val_fix = x_val\n","  bestbest = 0\n","\n","  for dim_redx in dim_reduction:\n","    print(f\"\\n=== Testing Dimensionality Reduction: {dim_redx} ===\")\n","    if dim_redx != 'PCA':\n","      pca_threshold = None\n","    for scaling_method in scaling_methods:\n","      for out in outs:\n","          print(f\"\\n=== Testing Scaling Method: {scaling_method}, Outlier: {out} ===\")\n","\n","          x_train = replace_default_new(x_train_fix.copy(), info)\n","          x_val = apply_saved_modes(x_val_fix.copy(), info)\n","\n","          # Rimuovi outlier\n","          x_train_filtered, y_train_filtered = remove_outliers(x_train, y_train, out)\n","\n","          # Preprocessing\n","          datasets, validation = preprocessing_pipeline(x_train_filtered, y_train_filtered, x_val, y_val,\n","              scaling_method, dim_redx, pca_threshold, target_count, num_datasets, random_seed\n","          )\n","\n","          results = {}\n","          for i, (x_train_processed, y_train_processed) in enumerate(datasets):\n","              x_val_processed, y_val_processed = validation[i]\n","              ds_name = f\"dataset_{i+1}\"\n","              metadata = {\n","                  'ds': ds_name,\n","                  'random': random_seed,\n","                  'outlier': out,\n","                  'dim_reduction': dim_redx,\n","                  'pca_threshold': pca_threshold,\n","                  'scaler': scaling_method,\n","                  'target count': target_count,\n","                  'info': info\n","              }\n","\n","              print(f\"--- Training Dataset {i+1}/{len(datasets)} ---\")\n","              best_model, best_score, best_report = train_svm_with_grid(\n","                  x_train_processed, y_train_processed,\n","                  x_val_processed, y_val_processed,\n","                  param_grid, metadata\n","              )\n","              if best_score > bestbest:\n","                bestbest = best_score\n","                joblib.dump(best_model, \"best_model.pkl\")\n","                print(best_score)\n","                print(best_report)\n","              if best_model:\n","                  results[f\"{scaling_method}_dataset_{i+1}\"] = {\n","                      'best_model': best_model,\n","                      'best_score': best_score,\n","                      'classification_report': best_report # Store the report in results\n","                  }\n","\n","  return results"]},{"cell_type":"markdown","source":["#Run"],"metadata":{"id":"MzUMaQu8S97F"}},{"cell_type":"code","source":["scaling_methods = ['standard', 'minmax', 'quantile', 'l1', 'l2']\n","out = ['no','base','isolation_forest', 'percentile',  'dynamic_threshold']\n","replace = ['no', 'mode', 'mode_all']\n","pca_threshold=0.99\n","dim_reduction = ['LDA', 'PCA', 'no']\n","param_grid = {\n","    'C': [0.5],\n","    'kernel': ['poly'],\n","    'gamma': [0.2],\n","    'degree': [5],\n","}"],"metadata":{"id":"DH6HtBM0qN_H","executionInfo":{"status":"ok","timestamp":1738587568991,"user_tz":-60,"elapsed":9,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["scaling_methods = ['standard', 'minmax', 'quantile', 'l1', 'l2']\n","scaling_methods = ['quantile', 'l1', 'l2']\n","out = ['no','base','isolation_forest', 'percentile',  'dynamic_threshold']\n","out = ['base','isolation_forest', 'percentile',  'dynamic_threshold']\n","replace = ['no', 'mode', 'mode_all']\n","pca_threshold=0.99\n","dim_reduction = ['LDA', 'PCA', 'no']\n","param_grid = {\n","    'C': [0.5],\n","    'kernel': ['poly'],\n","    'gamma': [0.2],\n","    'degree': [5],\n","}"],"metadata":{"id":"yfY9E0BA4xdb","executionInfo":{"status":"ok","timestamp":1738587568991,"user_tz":-60,"elapsed":9,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Esecuzione dell'esperimento\n","for r in replace:\n","  print(f\"\\n=== Testing Replace Value: {r} ===\")\n","  results = apply(\n","      X_train.copy(), y_train,\n","      X_val, y_val,\n","      scaling_methods, param_grid,\n","      dim_reduction=dim_reduction, pca_threshold=pca_threshold,\n","      target_count=15000, num_datasets=5, random_seed=19,\n","      outs = out,\n","      info = r\n","  )\n","\n","  # Analisi dei risultati\n","  for key, value in results.items():\n","      print(f\"\\n=== Results for {key} ===\")\n","      print(f\"Best Model: {value['best_model']}\")\n","      print(\"Classification Report:\")\n","      print(value['classification_report'])\n","\n","#"],"metadata":{"id":"UnXZWbxKNS-0","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1738589572274,"user_tz":-60,"elapsed":2003290,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}},"outputId":"1a7cc82d-2b47-4311-a928-d7550bb88224"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Testing Replace Value: no ===\n","\n","=== Testing Dimensionality Reduction: LDA ===\n","\n","=== Testing Scaling Method: quantile, Outlier: base ===\n","  Rimosse  927  istanze\n","  Dataset bilanciato 1:\n","  Numero di colonne selezionate (componenti discriminanti): 9\n","  Dataset bilanciato 2:\n","  Numero di colonne selezionate (componenti discriminanti): 9\n","  Dataset bilanciato 3:\n","  Numero di colonne selezionate (componenti discriminanti): 9\n","  Dataset bilanciato 4:\n","  Numero di colonne selezionate (componenti discriminanti): 9\n","  Dataset bilanciato 5:\n","  Numero di colonne selezionate (componenti discriminanti): 9\n","--- Training Dataset 1/5 ---\n","Valutando configurazione: {'C': 0.5, 'kernel': 'poly', 'gamma': 0.2, 'degree': 5}\n"," Validation score: 0.9734517577270296 - Train score 0.98154\n","0.9734517577270296\n","{'backdoor': {'precision': 0.7929399367755532, 'recall': 0.9986728599867286, 'f1-score': 0.8839941262848752, 'support': 1507.0}, 'ddos': {'precision': 0.9967364393427864, 'recall': 0.9682956160489778, 'f1-score': 0.9823102090611656, 'support': 18294.0}, 'dos': {'precision': 0.9733044733044733, 'recall': 0.9955719557195571, 'f1-score': 0.9843122947829259, 'support': 5420.0}, 'injection': {'precision': 0.8382949932341002, 'recall': 0.9336850037678975, 'f1-score': 0.8834224598930481, 'support': 1327.0}, 'mitm': {'precision': 0.40707964601769914, 'recall': 0.92, 'f1-score': 0.5644171779141104, 'support': 50.0}, 'normal': {'precision': 0.957079427725703, 'recall': 0.9542547958681751, 'f1-score': 0.9556650246305419, 'support': 2033.0}, 'password': {'precision': 0.9669357939254133, 'recall': 0.9757516973811833, 'f1-score': 0.9713237423964468, 'support': 5155.0}, 'ransomware': {'precision': 0.23937360178970918, 'recall': 0.963963963963964, 'f1-score': 0.3835125448028674, 'support': 111.0}, 'scanning': {'precision': 0.9993295019157088, 'recall': 0.9739089848308051, 'f1-score': 0.9864555017137454, 'support': 21425.0}, 'xss': {'precision': 0.9810665825181445, 'recall': 0.9750666457581935, 'f1-score': 0.9780574125049154, 'support': 6377.0}, 'accuracy': 0.9734517577270296, 'macro avg': {'precision': 0.815214039654929, 'recall': 0.9659171523325482, 'f1-score': 0.8573470493984642, 'support': 61699.0}, 'weighted avg': {'precision': 0.9799364937681853, 'recall': 0.9734517577270296, 'f1-score': 0.9757459478619597, 'support': 61699.0}}\n","--- Training Dataset 2/5 ---\n","Valutando configurazione: {'C': 0.5, 'kernel': 'poly', 'gamma': 0.2, 'degree': 5}\n"," Validation score: 0.973954196988606 - Train score 0.98166\n","0.973954196988606\n","{'backdoor': {'precision': 0.7933579335793358, 'recall': 0.9986728599867286, 'f1-score': 0.8842538190364277, 'support': 1507.0}, 'ddos': {'precision': 0.9961246840775063, 'recall': 0.9694981961298786, 'f1-score': 0.9826310978143439, 'support': 18294.0}, 'dos': {'precision': 0.9726076770589296, 'recall': 0.9957564575645756, 'f1-score': 0.9840459476707084, 'support': 5420.0}, 'injection': {'precision': 0.8469945355191257, 'recall': 0.9344385832705351, 'f1-score': 0.8885704048728055, 'support': 1327.0}, 'mitm': {'precision': 0.3898305084745763, 'recall': 0.92, 'f1-score': 0.5476190476190477, 'support': 50.0}, 'normal': {'precision': 0.971571072319202, 'recall': 0.9581898671913428, 'f1-score': 0.9648340762753839, 'support': 2033.0}, 'password': {'precision': 0.9668784902753707, 'recall': 0.9740058195926286, 'f1-score': 0.9704290684190182, 'support': 5155.0}, 'ransomware': {'precision': 0.2482598607888631, 'recall': 0.963963963963964, 'f1-score': 0.3948339483394834, 'support': 111.0}, 'scanning': {'precision': 0.9988995741830534, 'recall': 0.9744690781796966, 'f1-score': 0.9865331002220857, 'support': 21425.0}, 'xss': {'precision': 0.9807449494949495, 'recall': 0.9744393915634311, 'f1-score': 0.9775820026744277, 'support': 6377.0}, 'accuracy': 0.973954196988606, 'macro avg': {'precision': 0.8165269285770913, 'recall': 0.9663434217442781, 'f1-score': 0.8581332512943731, 'support': 61699.0}, 'weighted avg': {'precision': 0.9801834005717794, 'recall': 0.973954196988606, 'f1-score': 0.9761466947774275, 'support': 61699.0}}\n","--- Training Dataset 3/5 ---\n","Valutando configurazione: {'C': 0.5, 'kernel': 'poly', 'gamma': 0.2, 'degree': 5}\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-20-f7eb6e8ba9e0>\", line 4, in <cell line: 0>\n","    results = apply(\n","              ^^^^^^\n","  File \"<ipython-input-17-d69a0247e225>\", line 47, in apply\n","    best_model, best_score, best_report = train_svm_with_grid(\n","                                          ^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-16-029838fface6>\", line 47, in train_svm_with_grid\n","    thread.join(timeout=2700)  # 2700 secondi = 45 minuti\n","    ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n","    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n","  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n","    if lock.acquire(block, timeout):\n","       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","          ^^^^^^^^^^^^^^^^^^^^^^^^\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n","    traceback_info = getframeinfo(tb, context)\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/inspect.py\", line 1688, in getframeinfo\n","    lines, lnum = findsource(frame)\n","                  ^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 182, in findsource\n","    lines = linecache.getlines(file, globals_dict)\n","            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/linecache.py\", line 46, in getlines\n","    return updatecache(filename, module_globals)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/linecache.py\", line 136, in updatecache\n","    with tokenize.open(fullname) as fp:\n","         ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/tokenize.py\", line 398, in open\n","    encoding, lines = detect_encoding(buffer.readline)\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/tokenize.py\", line 367, in detect_encoding\n","    first = read_or_stop()\n","            ^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/tokenize.py\", line 325, in read_or_stop\n","    return readline()\n","           ^^^^^^^^^^\n","KeyboardInterrupt\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m<ipython-input-20-f7eb6e8ba9e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n=== Testing Replace Value: {r} ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   results = apply(\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-d69a0247e225>\u001b[0m in \u001b[0;36mapply\u001b[0;34m(x_train, y_train, x_val, y_val, scaling_methods, param_grid, dim_reduction, pca_threshold, target_count, num_datasets, random_seed, outs, info)\u001b[0m\n\u001b[1;32m     46\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- Training Dataset {i+1}/{len(datasets)} ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m               best_model, best_score, best_report = train_svm_with_grid(\n\u001b[0m\u001b[1;32m     48\u001b[0m                   \u001b[0mx_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_processed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-029838fface6>\u001b[0m in \u001b[0;36mtrain_svm_with_grid\u001b[0;34m(x_train, y_train, x_val, y_val, param_grid, metadata)\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2700\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 2700 secondi = 45 minuti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;31m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}]},{"cell_type":"code","source":["model = joblib.load(\"best_model.pkl\")\n","print(model)"],"metadata":{"id":"fngDNmyjFMIb","executionInfo":{"status":"aborted","timestamp":1738589572275,"user_tz":-60,"elapsed":8,"user":{"displayName":"Benedetta Bottari","userId":"06521195039600113604"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["oK4AXarlSXJf","FJgi_sXUxr9c","EprNSrtG020W","xuYxMmVa9Yyh"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}